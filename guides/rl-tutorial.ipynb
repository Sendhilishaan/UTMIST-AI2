{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a31d68",
   "metadata": {},
   "source": [
    "# [What is Reinforcement Learning?](https://gymnasium.farama.org/introduction/basic_usage/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13672a",
   "metadata": {},
   "source": [
    "<img src=\"https://gymnasium.farama.org/_images/AE_loop_dark.png\" alt=\"Alt text\" width=\"50%\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8f81e",
   "metadata": {},
   "source": [
    "# 1. Load a game\n",
    "> run install.sh first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eac1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .. # Should be root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fee40",
   "metadata": {},
   "source": [
    "> ## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment.environment import WarehouseBrawl, RenderMode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Environment\n",
    "env = WarehouseBrawl(mode=RenderMode.RGB_ARRAY)\n",
    "\n",
    "# Arbitary Action\n",
    "env.step({\n",
    "    0: np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), # agent 1\n",
    "    1: np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) # agent 2\n",
    "}) \n",
    "\n",
    "img = env.camera.get_frame(env, mode=RenderMode.RGB_ARRAY)\n",
    "plt.imshow(np.rot90(img, -1))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8939ce49",
   "metadata": {},
   "source": [
    "> ## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.get_observation_space()\n",
    "\n",
    "print(\"observation.shape\", observation.shape)\n",
    "print(\"Lower bounds of the intervals\", observation.low, sep=\"\\n\")\n",
    "print(\"Upper bounds of the intervals\", observation.high, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.obs_helper.print_all_sections()\n",
    "\n",
    "for k, v in env.obs_helper.sections.items():\n",
    "    print(k, v) # key: (index start, index end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ba7ca",
   "metadata": {},
   "source": [
    "> ## Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa841c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = env.get_action_space()\n",
    "env.act_helper.sections.keys()\n",
    "\n",
    "print(actions.shape)\n",
    "\n",
    "# 1. W (Aim up)\n",
    "# 2. A (Left)\n",
    "# 3. S (Aim down/fastfall)\n",
    "# 4. D (Right)\n",
    "# 5. Space (Jump)\n",
    "# 6. H (Pickup/Throw)\n",
    "# 7. L (Dash/Dodge)\n",
    "# 8. J (Light Attack)\n",
    "# 9. K (Heavy Attack)\n",
    "# 10. G (Taunt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe2f99",
   "metadata": {},
   "source": [
    "# 2. Build an Agent and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c4af14",
   "metadata": {},
   "source": [
    "> ## Define Functions for Test\n",
    "> Don't need to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def visualize_with_pygame(env, window, video_writer=None):\n",
    "    img = np.rot90(env.camera.get_frame(env, mode=RenderMode.RGB_ARRAY), -1)\n",
    "    frame_height, frame_width = img.shape[:2]\n",
    "\n",
    "    if window is None:\n",
    "        window = pygame.display.set_mode((frame_width, frame_height))\n",
    "        pygame.display.set_caption('WarehouseBrawl Visualization')\n",
    "    \n",
    "    # Pygame UI rendering logic\n",
    "    if img.shape[0] != frame_height or img.shape[1] != frame_width:\n",
    "        img = np.resize(img, (frame_height, frame_width, 3))\n",
    "    surface = pygame.surfarray.make_surface(np.transpose(img, (1, 0, 2)))\n",
    "    window.blit(surface, (0, 0))\n",
    "    # pygame.display.flip()\n",
    "    \n",
    "    # Flip the display horizontally (mirror image)\n",
    "    surface = pygame.transform.flip(surface, True, False)\n",
    "    window.blit(surface, (0, 0))\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # If a video writer is provided, save the frame\n",
    "    if video_writer is not None:\n",
    "        # For most video writers, e.g., skvideo.io.FFmpegWriter\n",
    "        # Make sure img is in shape (height, width, 3) and dtype uint8\n",
    "        frame_to_save = np.flip(img, axis=1)  # Flip horizontally to match display\n",
    "        if frame_to_save.dtype != np.uint8:\n",
    "            frame_to_save = frame_to_save.astype(np.uint8)\n",
    "        video_writer.writeFrame(frame_to_save)\n",
    "    \n",
    "    return window\n",
    "\n",
    "def run_game_with_visualization(policy_func_agnet1, policy_func_agnet2, max_episode_length=300, save_video=False, save_video_path='game_video.mp4', delay_every_frame=0):\n",
    "    if save_video:\n",
    "        import skvideo.io\n",
    "        video_writer = skvideo.io.FFmpegWriter(save_video_path, outputdict={'-pix_fmt': 'yuv420p'})\n",
    "    else:\n",
    "        video_writer = None # Disable video recording (Use the code above to save video)\n",
    "\n",
    "    pygame.init()\n",
    "    env.reset()\n",
    "    observation, *_ = env.step({\n",
    "        0: np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), \n",
    "        1: np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    })\n",
    "\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    n_episode_length = 0\n",
    "    running = True\n",
    "    window = None\n",
    "\n",
    "    while running and not terminated and not truncated and n_episode_length < max_episode_length:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "                break\n",
    "\n",
    "        action = {  # step environment with random actions\n",
    "            0: policy_func_agnet1(observation),  # agent 1\n",
    "            1: policy_func_agnet2(observation)   # agent 2\n",
    "        }\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        print(\"Reward:\", reward, \" \"*64, end=\"\\r\")\n",
    "\n",
    "        window = visualize_with_pygame(env, window, video_writer=video_writer)\n",
    "\n",
    "        n_episode_length += 1\n",
    "        if delay_every_frame > 0:\n",
    "            time.sleep(delay_every_frame)\n",
    "    \n",
    "    if save_video:\n",
    "        video_writer.close()\n",
    "\n",
    "    pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196671f",
   "metadata": {},
   "source": [
    "> ## Policy (Agent)\n",
    "> Edit this function to build your own agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f20a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(observation):\n",
    "    if np.random.rand() < 0.05: # 5% chance to jump\n",
    "        return np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0])  # Jump\n",
    "    else:\n",
    "        return np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])  # No jump\n",
    "    \n",
    "    # return env.get_action_space().sample() # Random Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47310eb0",
   "metadata": {},
   "source": [
    "> ## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680c2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_game_with_visualization(\n",
    "    policy_func_agnet1=policy,\n",
    "    policy_func_agnet2=policy, \n",
    "    max_episode_length=100,\n",
    "    save_video=True,\n",
    "    save_video_path=\"game_video.mp4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc7c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# For a local video file (ensure the file is in the same directory or provide the full path)\n",
    "Video(\"./game_video.mp4\", width=640, height=360, embed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
